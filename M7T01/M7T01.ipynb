{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicis d'algoritmes de Classificació.\n",
        "# Ejercicios de algoritmos de Classificación\n",
        "# Classification Algorithm Exercises."
      ],
      "metadata": {
        "id": "iZYsMwXCkAOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exercici 1\n",
        "\n",
        "Crea almenys dos models de classificació diferents per intentar predir el millor les classes de l'arxiu adjunt.\n",
        "\n",
        "- Ejercicio 1\n",
        "\n",
        "Crea al menos dos modelos de clasificación diferentes para intentar predecir mejor las clases del archivo adjunto.\n",
        "\n",
        "- Exercise 1\n",
        "\n",
        "Create at least two different classification models to better predict the classes of the attached file."
      ],
      "metadata": {
        "id": "-fcH6L2FkwWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nHaUvqSjgpk",
        "outputId": "9f065b71-df8e-460f-9268-bc33df0913ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy"
      ],
      "metadata": {
        "id": "OYuTbnr4mjOa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Title of Database: Wine recognition data Updated Sept 21, 1998 by C.Blake : Added attribute information\n",
        "\n",
        "2. Sources:\n",
        "   (a) Forina, M. et al, PARVUS - An Extendible Package for Data       Exploration, Classification and Correlation. Institute of Pharmaceutical        and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.\n",
        "\n",
        "   (b) Stefan Aeberhard, email: stefan@coral.cs.jcu.edu.au\n",
        "   (c) July 1991\n",
        "3. Past Usage:\n",
        "\n",
        "   (1)\n",
        "   S. Aeberhard, D. Coomans and O. de Vel,\n",
        "   Comparison of Classifiers in High Dimensional Settings,\n",
        "   Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\n",
        "   Mathematics and Statistics, James Cook University of North Queensland.\n",
        "   (Also submitted to Technometrics).\n",
        "\n",
        "   The data was used with many others for comparing various\n",
        "   classifiers. The classes are separable, though only RDA\n",
        "   has achieved 100% correct classification.\n",
        "   (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\n",
        "   (All results using the leave-one-out technique)\n",
        "\n",
        "   In a classification context, this is a well posed problem\n",
        "   with \"well behaved\" class structures. A good data set\n",
        "   for first testing of a new classifier, but not very\n",
        "   challenging.\n",
        "\n",
        "   (2)\n",
        "   S. Aeberhard, D. Coomans and O. de Vel,\n",
        "   \"THE CLASSIFICATION PERFORMANCE OF RDA\"\n",
        "   Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\n",
        "   Mathematics and Statistics, James Cook University of North Queensland.\n",
        "   (Also submitted to Journal of Chemometrics).\n",
        "\n",
        "   Here, the data was used to illustrate the superior performance of\n",
        "   the use of a new appreciation function with RDA.\n",
        "\n",
        "4. Relevant Information:\n",
        "\n",
        "   -- These data are the results of a chemical analysis of\n",
        "      wines grown in the same region in Italy but derived from three\n",
        "      different cultivars.\n",
        "      The analysis determined the quantities of 13 constituents\n",
        "      found in each of the three types of wines.\n",
        "\n",
        "   -- I think that the initial data set had around 30 variables, but\n",
        "      for some reason I only have the 13 dimensional version.\n",
        "      I had a list of what the 30 or so variables were, but a.)\n",
        "      I lost it, and b.), I would not know which 13 variables\n",
        "      are included in the set.\n",
        "\n",
        "   -- The attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it):\n",
        "\n",
        " \t1) Alcohol\n",
        "\n",
        " \t2) Malic acid\n",
        "\n",
        " \t3) Ash\n",
        "\n",
        "  4) Alcalinity of ash  \n",
        "\n",
        "  5) Magnesium\n",
        "\n",
        "  6) Total phenols\n",
        "\n",
        "  7) Flavanoids\n",
        "\n",
        "  8) Nonflavanoid phenols\n",
        "\n",
        "  9) Proanthocyanins\n",
        "\n",
        "  10)Color intensity\n",
        "\n",
        "  11)Hue\n",
        "\n",
        "  12)OD280/OD315 of diluted wines\n",
        "\n",
        "  13)Proline            \n",
        "\n",
        "5. Number of Instances:\n",
        "\n",
        " \tclass 1 59\n",
        "\n",
        "  class 2 71\n",
        "\n",
        "  class 3 48\n",
        "\n",
        "6. Number of Attributes:\n",
        "\n",
        "\t13\n",
        "\n",
        "7. For Each Attribute:\n",
        "\n",
        "\tAll attributes are continuous\n",
        "\n",
        "\tNo statistics available, but suggest to standardise\n",
        "\tvariables for certain uses (e.g. for us with classifiers\n",
        "\twhich are NOT scale invariant)\n",
        "\n",
        "\tNOTE: 1st attribute is class identifier (1-3)\n",
        "\n",
        "8. Missing Attribute Values:\n",
        "\n",
        "\tNone\n",
        "\n",
        "9. Class Distribution: number of instances per class:\n",
        "\n",
        "\n",
        "  class 1 59\n",
        "\n",
        "  class 2 71\n",
        "\n",
        "  class 3 48\n"
      ],
      "metadata": {
        "id": "jf_6609InBr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/DS/M7T01/wineData.txt', sep=',',header=None)"
      ],
      "metadata": {
        "id": "s0dDDqJnn2Ku"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "95y0ZkC8_4Tv",
        "outputId": "d8981436-6717-47dc-961a-16e2c2b49dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0      1     2     3     4    5     6     7     8     9      10    11  \\\n",
              "0     1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29   5.64  1.04   \n",
              "1     1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28   4.38  1.05   \n",
              "2     1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81   5.68  1.03   \n",
              "3     1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18   7.80  0.86   \n",
              "4     1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04   \n",
              "..   ..    ...   ...   ...   ...  ...   ...   ...   ...   ...    ...   ...   \n",
              "173   3  13.71  5.65  2.45  20.5   95  1.68  0.61  0.52  1.06   7.70  0.64   \n",
              "174   3  13.40  3.91  2.48  23.0  102  1.80  0.75  0.43  1.41   7.30  0.70   \n",
              "175   3  13.27  4.28  2.26  20.0  120  1.59  0.69  0.43  1.35  10.20  0.59   \n",
              "176   3  13.17  2.59  2.37  20.0  120  1.65  0.68  0.53  1.46   9.30  0.60   \n",
              "177   3  14.13  4.10  2.74  24.5   96  2.05  0.76  0.56  1.35   9.20  0.61   \n",
              "\n",
              "       12    13  \n",
              "0    3.92  1065  \n",
              "1    3.40  1050  \n",
              "2    3.17  1185  \n",
              "3    3.45  1480  \n",
              "4    2.93   735  \n",
              "..    ...   ...  \n",
              "173  1.74   740  \n",
              "174  1.56   750  \n",
              "175  1.56   835  \n",
              "176  1.62   840  \n",
              "177  1.60   560  \n",
              "\n",
              "[178 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcde9ab6-7ad5-4ce8-a5ca-1561ad4fc89f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>3</td>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>3</td>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>3</td>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>3</td>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>3</td>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcde9ab6-7ad5-4ce8-a5ca-1561ad4fc89f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fcde9ab6-7ad5-4ce8-a5ca-1561ad4fc89f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fcde9ab6-7ad5-4ce8-a5ca-1561ad4fc89f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-004784f8-2930-410a-94da-dc72f890d36c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-004784f8-2930-410a-94da-dc72f890d36c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-004784f8-2930-410a-94da-dc72f890d36c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols =[\n",
        "    \"class\",\n",
        "    \"Alcohol\",\n",
        "    \"Malic acid\",\n",
        "    \"Ash\",\n",
        "    \"Alcalinity of ash\",\n",
        "    \"Magnesium\",\n",
        "    \"Total phenols\",\n",
        "    \"Flavanoids\",\n",
        "    \"Nonflavanoid phenols\",\n",
        "    \"Proanthocyanins\",\n",
        "    \"Color intensity\",\n",
        "    \"Hue\",\n",
        "    \"OD280/OD315 of diluted wines\",\n",
        "    \"Proline\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "sG-8LJLZAuoD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = cols\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "nV-MY3sZB3lF",
        "outputId": "ba75ad12-c2c4-42ca-8d6c-995cc69a4d06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
              "0      1    14.23        1.71  2.43               15.6        127   \n",
              "1      1    13.20        1.78  2.14               11.2        100   \n",
              "2      1    13.16        2.36  2.67               18.6        101   \n",
              "\n",
              "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
              "0           2.80        3.06                  0.28             2.29   \n",
              "1           2.65        2.76                  0.26             1.28   \n",
              "2           2.80        3.24                  0.30             2.81   \n",
              "\n",
              "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
              "0             5.64  1.04                          3.92     1065  \n",
              "1             4.38  1.05                          3.40     1050  \n",
              "2             5.68  1.03                          3.17     1185  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-209dbc8e-b025-47b9-9828-754687c52acc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-209dbc8e-b025-47b9-9828-754687c52acc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-209dbc8e-b025-47b9-9828-754687c52acc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-209dbc8e-b025-47b9-9828-754687c52acc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-963f2cd1-7cd0-4bf6-8e26-b140b325256a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-963f2cd1-7cd0-4bf6-8e26-b140b325256a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-963f2cd1-7cd0-4bf6-8e26-b140b325256a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "_LzEA9gkCHPM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X = df.drop(\"class\", axis=1)\n",
        "y = df[\"class\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "xRLPJKNJDy9X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
      ],
      "metadata": {
        "id": "d8lfmEfk6jwN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Support Vector Machine': SVC()\n",
        "\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    confusion = confusion_matrix(y_test, predictions)\n",
        "    report = classification_report(y_test, predictions)\n",
        "\n",
        "    print(model_name + \":\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Confusion Matrix:\\n\", confusion)\n",
        "    print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-54qnSWIPTF",
        "outputId": "91a25735-11f3-4078-f6e2-8ea4b13d5318"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.9722222222222222\n",
            "Confusion Matrix:\n",
            " [[13  1  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0  8]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.93      0.96        14\n",
            "           2       0.93      1.00      0.97        14\n",
            "           3       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.98      0.98        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[14  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0  8]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00        14\n",
            "           3       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "K-Nearest Neighbors:\n",
            "Accuracy: 0.7222222222222222\n",
            "Confusion Matrix:\n",
            " [[12  0  2]\n",
            " [ 0 11  3]\n",
            " [ 2  3  3]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.86      0.86        14\n",
            "           2       0.79      0.79      0.79        14\n",
            "           3       0.38      0.38      0.38         8\n",
            "\n",
            "    accuracy                           0.72        36\n",
            "   macro avg       0.67      0.67      0.67        36\n",
            "weighted avg       0.72      0.72      0.72        36\n",
            "\n",
            "Support Vector Machine:\n",
            "Accuracy: 0.8055555555555556\n",
            "Confusion Matrix:\n",
            " [[14  0  0]\n",
            " [ 0 11  3]\n",
            " [ 0  4  4]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.73      0.79      0.76        14\n",
            "           3       0.57      0.50      0.53         8\n",
            "\n",
            "    accuracy                           0.81        36\n",
            "   macro avg       0.77      0.76      0.76        36\n",
            "weighted avg       0.80      0.81      0.80        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exercici 2\n",
        "\n",
        "Compara els models de classificació utilitzant la precisió (accuracy), una matriu de confusió i d’altres mètriques més avançades.\n",
        "\n",
        "- Ejercicio 2\n",
        "\n",
        "Compara los modelos de clasificación utilizando la precisión (accuracy), una matriz de confusión y otras métricas más avanzadas.\n",
        "\n",
        "- Exercise 2\n",
        "\n",
        "Compare the classification models using accuracy, a confusion matrix, and other advanced metrics."
      ],
      "metadata": {
        "id": "zqGcDXgJl26F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este informe, se muestra el rendimiento del modelo de Regresión Logística:\n",
        "- La precisión del modelo es 0.972, lo que indica que el 97.2% de las predicciones son correctas.\n",
        "- La matriz de confusión muestra cómo se clasificaron las instancias en las diferentes clases. Por ejemplo, el modelo clasificó correctamente 13 instancias de la clase 1, 14 instancias de la clase 2 y 8 instancias de la clase 3.\n",
        "- El informe de clasificación proporciona información detallada sobre la precisión, recuperación y puntuación F1 para cada clase y en general. En general, el modelo muestra un rendimiento muy bueno en todas las métricas de evaluación.\n",
        "\n",
        "Este modelo parece tener un rendimiento sólido en términos de precisión y recuperación para todas las clases.\n",
        "\n",
        "Random Forest:\n",
        "- La precisión del modelo es 1.0, lo que indica que el 100% de las predicciones son correctas.\n",
        "- La matriz de confusión muestra que todas las instancias se clasificaron correctamente en sus respectivas clases.\n",
        "- El informe de clasificación también muestra puntuaciones perfectas en precisión, recuperación y puntuación F1 para todas las clases y en general.\n",
        "\n",
        "Este modelo parece tener un rendimiento excepcionalmente alto y preciso en la clasificación de las instancias en todas las clases.\n",
        "\n",
        "K-Nearest Neighbors (KNN):\n",
        "- La precisión del modelo es 0.7222222222222222, lo que indica que alrededor del 72.22% de las predicciones son correctas.\n",
        "- La matriz de confusión muestra cómo se distribuyen las instancias clasificadas en las clases. Algunas instancias fueron clasificadas incorrectamente.\n",
        "- El informe de clasificación proporciona más detalles sobre la precisión, la recuperación y la puntuación F1 para cada clase individual, así como sus valores promedio ponderados y macro. En este caso, el modelo tiene un rendimiento relativamente bueno para la clase 1, pero su rendimiento es menos satisfactorio para la clase 3.\n",
        "\n",
        "Este modelo parece tener un rendimiento moderado en términos de precisión y puede beneficiarse de ajustes y optimizaciones.\n",
        "\n",
        "Máquinas de Vectores de Soporte (SVM):\n",
        "- La precisión del modelo es 0.8055555555555556, lo que indica que alrededor del 80.56% de las predicciones son correctas.\n",
        "- La matriz de confusión muestra cómo se distribuyen las instancias clasificadas en las clases. El modelo tuvo algunos errores en la clasificación de las clases 2 y 3.\n",
        "- El informe de clasificación proporciona más detalles sobre la precisión, la recuperación y la puntuación F1 para cada clase individual, así como sus valores promedio ponderados y macro. En este caso, el modelo tiene un rendimiento sólido para la clase 1, pero su rendimiento es menos consistente para las clases 2 y 3.\n",
        "\n",
        "Este modelo podría beneficiarse de ajustes de hiperparámetros o técnicas de selección de características para mejorar su rendimiento."
      ],
      "metadata": {
        "id": "avCD6cNgRYRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exercici 3\n",
        "\n",
        "Entrena’ls usant els diferents paràmetres que admeten per tal de millorar-ne la predicció.\n",
        "\n",
        "- Ejercicio 3\n",
        "\n",
        "Entrenalos utilizando los diferentes parámetros que admiten para intentar mejorar su predicción.\n",
        "\n",
        "- Exercise 3\n",
        "\n",
        "Train them using the different parameters they allow to improve their prediction."
      ],
      "metadata": {
        "id": "pNfK09hDl7pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
      ],
      "metadata": {
        "id": "VM3_s3ywWW3b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los modelos con sus hiperparámetros para GridSearchCV o RandomizedSearchCV\n",
        "models = {\n",
        "    'Logistic Regression': (LogisticRegression(), {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'max_iter': [100, 200, 300]\n",
        "    }),\n",
        "    'Random Forest': (RandomForestClassifier(), {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [None, 10, 20]\n",
        "    }),\n",
        "    'K-Nearest Neighbors': (KNeighborsClassifier(), {\n",
        "        'n_neighbors': [3, 5, 7],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    }),\n",
        "    'Support Vector Machine': (SVC(), {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf']\n",
        "    })\n",
        "}\n",
        "\n",
        "# Realizar GridSearchCV o RandomizedSearchCV para cada modelo\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    print(\"Training\", model_name)\n",
        "\n",
        "    # Realizar búsqueda de parámetros\n",
        "    search = GridSearchCV(model, param_grid, cv=5)  # Cambia a RandomizedSearchCV si lo prefieres\n",
        "\n",
        "    # Entrenar el mejor modelo encontrado\n",
        "    search.fit(X_train, y_train)\n",
        "    best_model = search.best_estimator_\n",
        "\n",
        "    # Predecir en el conjunto de prueba\n",
        "    predictions = best_model.predict(X_test)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    confusion = confusion_matrix(y_test, predictions)\n",
        "    report = classification_report(y_test, predictions)\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(model_name + \":\")\n",
        "    print(\"Best Parameters:\", search.best_params_)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Confusion Matrix:\\n\", confusion)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "    print(\"------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taKav46nX6gu",
        "outputId": "af87fd89-610f-471b-cf48-e3ee5be2d6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Best Parameters: {'C': 0.1, 'max_iter': 300}\n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[14  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0  8]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "------------\n",
            "Training Random Forest\n",
            "Random Forest:\n",
            "Best Parameters: {'max_depth': 10, 'n_estimators': 150}\n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[14  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0  8]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "------------\n",
            "Training K-Nearest Neighbors\n",
            "K-Nearest Neighbors:\n",
            "Best Parameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
            "Accuracy: 0.75\n",
            "Confusion Matrix:\n",
            " [[12  0  2]\n",
            " [ 0 10  4]\n",
            " [ 1  2  5]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.86      0.89        14\n",
            "           1       0.83      0.71      0.77        14\n",
            "           2       0.45      0.62      0.53         8\n",
            "\n",
            "    accuracy                           0.75        36\n",
            "   macro avg       0.74      0.73      0.73        36\n",
            "weighted avg       0.78      0.75      0.76        36\n",
            "\n",
            "------------\n",
            "Training Support Vector Machine\n",
            "Support Vector Machine:\n",
            "Best Parameters: {'C': 0.1, 'kernel': 'linear'}\n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[14  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0  8]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados de la optimización de parámetros para cada modelo son los siguientes:\n",
        "\n",
        "Logistic Regression:\n",
        "\n",
        "    Mejores parámetros: {'C': 0.1, 'max_iter': 300}\n",
        "    Accuracy: 1.0\n",
        "    \n",
        "Random Forest:\n",
        "\n",
        "    Mejores parámetros: {'max_depth': 10, 'n_estimators': 150}\n",
        "    Accuracy: 1.0\n",
        "    \n",
        "K-Nearest Neighbors:\n",
        "\n",
        "    Mejores parámetros: {'n_neighbors': 7, 'weights': 'distance'}\n",
        "    Accuracy: 0.75\n",
        "    \n",
        "Support Vector Machine:\n",
        "\n",
        "    Mejores parámetros: {'C': 0.1, 'kernel': 'linear'}\n",
        "    Accuracy: 1.0\n",
        "    "
      ],
      "metadata": {
        "id": "-HPiNErXYkvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exercici 4\n",
        "\n",
        "Compara el seu rendiment fent servir l’aproximació traint/test o cross-validation.\n",
        "\n",
        "- Ejercicio 4\n",
        "\n",
        "Compara su rendimiento utilizando la aproximación entrenamiento/prueba o validación cruzada.\n",
        "\n",
        "- Exercise 4\n",
        "\n",
        "Compare their performance using the train/test approach or cross-validation."
      ],
      "metadata": {
        "id": "bs0uQqcvmC1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los modelos con sus hiperparámetros para GridSearchCV o RandomizedSearchCV\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(C=0.1, max_iter=300),\n",
        "    'Random Forest': RandomForestClassifier(max_depth=20, n_estimators=100),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=7, weights='distance'),\n",
        "    'Support Vector Machine': SVC(C=0.1, kernel='linear')\n",
        "}\n",
        "\n",
        "# Realizar validación cruzada para cada modelo\n",
        "for model_name, model in models.items():\n",
        "    print(\"Training\", model_name)\n",
        "\n",
        "    # Realizar validación cruzada con 5 folds\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(model_name + \":\")\n",
        "    print(\"Promedio de Validación Cruzada:\", np.mean(cv_scores))\n",
        "    print(\"------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kId5afniFCAA",
        "outputId": "aab9a2e5-f521-44f0-c098-ac87457fdebe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Promedio de Validación Cruzada: 0.9504926108374384\n",
            "------------\n",
            "Training Random Forest\n",
            "Random Forest:\n",
            "Promedio de Validación Cruzada: 0.9716748768472907\n",
            "------------\n",
            "Training K-Nearest Neighbors\n",
            "K-Nearest Neighbors:\n",
            "Promedio de Validación Cruzada: 0.7187192118226602\n",
            "------------\n",
            "Training Support Vector Machine\n",
            "Support Vector Machine:\n",
            "Promedio de Validación Cruzada: 0.9576354679802955\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression muestra un accuracy perfecta en el conjunto de entrenamiento/prueba, lo que sugiere que está ajustando muy bien los datos de entrenamiento. Sin embargo, en la validación cruzada, donde se evalúa en conjuntos de datos diferentes, la precisión promedio es ligeramente más baja (0.9505). Esto indica que el modelo puede tener un rendimiento un poco más bajo en datos no vistos, pero aún es muy sólido.\n",
        "\n",
        "Random Forest también tiene un accuracy perfecta en el conjunto de entrenamiento/prueba. Sin embargo, en la validación cruzada, su rendimiento promedio es incluso mejor (0.9717), lo que sugiere que es un modelo altamente generalizable y estable en datos no vistos.\n",
        "\n",
        "K-Nearest Neighbors tiene un accuracy de 0.75, lo que indica un rendimiento moderado. Sin embargo, en la validación cruzada, su rendimiento promedio es más bajo (0.7187), lo que sugiere que el modelo puede no ser tan confiable en datos no vistos y puede estar sobreajustando en ciertos conjuntos de entrenamiento.\n",
        "\n",
        "SVM muestra un accuracy perfecta en el conjunto de entrenamiento/prueba. Sin embargo, en la validación cruzada, su rendimiento promedio es ligeramente más bajo (0.9576), lo que sugiere que puede haber una pequeña pérdida de rendimiento en datos no vistos, pero aún es un modelo confiable."
      ],
      "metadata": {
        "id": "7-BbBSXyH21F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exercici 5\n",
        "\n",
        "Aplica algun procés d'enginyeria per millorar els resultats (normalització, estandardització, mostreig...).\n",
        "\n",
        "- Ejercicio 5\n",
        "\n",
        "Aplica algún proceso de ingeniería para mejorar los resultados (normalización, estandarización, muestreo...).\n",
        "\n",
        "- Exercise 5\n",
        "\n",
        "Apply some engineering processes to enhance the results (normalization, standardization, sampling...).\n"
      ],
      "metadata": {
        "id": "RqfrlIITmJX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Definir los modelos con sus hiperparámetros\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Support Vector Machine': SVC()\n",
        "}\n",
        "\n",
        "# Aplicar preprocesamiento y entrenar los modelos\n",
        "for model_name, model in models.items():\n",
        "    print(\"Training\", model_name)\n",
        "\n",
        "    # Crear un pipeline con preprocesamiento y modelo\n",
        "    pipeline = make_pipeline(StandardScaler(), model)\n",
        "\n",
        "    # Realizar validación cruzada\n",
        "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
        "\n",
        "    # Entrenar el modelo final\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    predictions = pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(model_name + \":\")\n",
        "    print(\"Promedio de Validación Cruzada:\", cv_scores.mean())\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dkJM1JHP79G",
        "outputId": "7862d369-a75f-4f21-d411-4bbbdbea5822"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression\n",
            "Logistic Regression:\n",
            "Promedio de Validación Cruzada: 0.993103448275862\n",
            "Accuracy: 0.9722222222222222\n",
            "------------\n",
            "Training Random Forest\n",
            "Random Forest:\n",
            "Promedio de Validación Cruzada: 0.9862068965517242\n",
            "Accuracy: 1.0\n",
            "------------\n",
            "Training K-Nearest Neighbors\n",
            "K-Nearest Neighbors:\n",
            "Promedio de Validación Cruzada: 0.9650246305418719\n",
            "Accuracy: 0.9722222222222222\n",
            "------------\n",
            "Training Support Vector Machine\n",
            "Support Vector Machine:\n",
            "Promedio de Validación Cruzada: 0.9862068965517242\n",
            "Accuracy: 0.9722222222222222\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression:\n",
        "\n",
        "    El promedio de validación cruzada es aproximadamente 0.993, lo que sugiere que el modelo es capaz de generalizar bien en diferentes conjuntos de datos de entrenamiento.\n",
        "    La accuracy en el conjunto de prueba es del 0.972, lo que significa que el modelo predice correctamente la clase en un 97.2% de las instancias del conjunto de prueba.\n",
        "\n",
        "Random Forest:\n",
        "\n",
        "    El promedio de validación cruzada es aproximadamente 0.986, indicando que el modelo tiene una buena capacidad de generalización.\n",
        "    La accuracy en el conjunto de prueba es del 1.0, lo que significa que el modelo predice todas las instancias correctamente en el conjunto de prueba.\n",
        "\n",
        "K-Nearest Neighbors:\n",
        "\n",
        "    El promedio de validación cruzada es aproximadamente 0.965, lo que sugiere una capacidad razonable de generalización.\n",
        "    La accuracy en el conjunto de prueba es del 0.972, lo que indica que el modelo tiene un rendimiento similar al conjunto de entrenamiento.\n",
        "\n",
        "Support Vector Machine:\n",
        "\n",
        "    El promedio de validación cruzada es aproximadamente 0.986, lo que indica una buena capacidad de generalización.\n",
        "    La acccuracy en el conjunto de prueba es del 0.972, lo que demuestra que el modelo tiene un buen rendimiento en el conjunto de prueba."
      ],
      "metadata": {
        "id": "Kb08GCH2RMr_"
      }
    }
  ]
}